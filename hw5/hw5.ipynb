{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def read_data(filename):\n",
    "    with open(filename) as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "        labels = []\n",
    "\n",
    "        rows = []\n",
    "        cols = []\n",
    "        vals = []\n",
    "\n",
    "        max_row = 0\n",
    "        max_col = 0\n",
    "\n",
    "        for line in lines:\n",
    "            label = int(line.split()[0])\n",
    "            if (label != 2 and label != 6):\n",
    "                continue\n",
    "            labels.append(label)\n",
    "\n",
    "            feature_row = line.split()[1:]\n",
    "            for feature in feature_row:\n",
    "                col, val = feature.split(':')\n",
    "\n",
    "                rows.append(max_row)\n",
    "                cols.append(int(col))\n",
    "                vals.append(float(val))\n",
    "\n",
    "                if int(col) > max_col:\n",
    "                    max_col = int(col)\n",
    "\n",
    "            max_row += 1\n",
    "\n",
    "        # change to numpy arrays\n",
    "        labels = np.array(labels)\n",
    "        features = csr_matrix((vals, (rows, cols)), shape=(max_row, max_col + 1)).toarray()\n",
    "\n",
    "        print(f\">> read {filename}\")\n",
    "        print(\"read labels: \", labels.shape)\n",
    "        print(\"read features: \", features.shape)\n",
    "\n",
    "    return labels, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from liblinear.liblinearutil import *\n",
    "\n",
    "def problem10(result_file, round=1):\n",
    "    labels, features = read_data('mnist.scale.txt')\n",
    "    lables_t, features_t = read_data('mnist.scale.t.txt')\n",
    "\n",
    "    with open(result_file, 'w') as f:\n",
    "        f.write(\"lambda,eout,non-zero\\n\")\n",
    "\n",
    "    lambdas = [0.01, 0.1, 1, 10, 100, 1000]\n",
    "\n",
    "    for i in range(round):\n",
    "        # find best lambda with min ein\n",
    "        min_ein = 1\n",
    "        best_lambda = 0\n",
    "        best_model = None\n",
    "\n",
    "        for l in lambdas:\n",
    "            cost = 1 / l\n",
    "            # train\n",
    "            prob = problem(labels, features)\n",
    "            param = parameter(f'-s 6 -c {cost}')\n",
    "            m = train(prob, param)\n",
    "\n",
    "            _, p_acc, _ = predict(labels, features, m)\n",
    "            ein = 1 - p_acc[0] / 100\n",
    "            # print(f\"train on lambda: {l}, ein: {ein}\")\n",
    "\n",
    "            if ein < min_ein:\n",
    "                min_ein = ein\n",
    "                best_lambda = l\n",
    "                best_model = m\n",
    "            elif ein == min_ein:\n",
    "                # choose larger lambda\n",
    "                if l > best_lambda:\n",
    "                    best_lambda = l\n",
    "                    best_model = m\n",
    "\n",
    "        # test on best lambda\n",
    "        _, p_acc_t, _ = predict(lables_t, features_t, best_model)\n",
    "        eout = 1 - p_acc_t[0] / 100\n",
    "\n",
    "        # calculate non-zero components of model\n",
    "        nz = np.count_nonzero(best_model.get_decfun()[0])\n",
    "\n",
    "        with open(result_file, 'a') as f:\n",
    "            f.write(f\"{best_lambda},{eout},{nz}\\n\")\n",
    "\n",
    "    print(\"problem 10 done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from liblinear.liblinearutil import *\n",
    "\n",
    "def problem11(result_file, round=1):\n",
    "    labels, features = read_data('mnist.scale.txt')\n",
    "    lables_t, features_t = read_data('mnist.scale.t.txt')\n",
    "\n",
    "    with open(result_file, 'w') as f:\n",
    "        f.write(\"lambda,eout\\n\")\n",
    "\n",
    "    lambdas = [0.01, 0.1, 1, 10, 100, 1000]\n",
    "\n",
    "    for i in range(round):\n",
    "        # randomly select 8000 samples for training, others for validation\n",
    "        idx = np.random.permutation(labels.shape[0])\n",
    "        idx_train = idx[:8000]\n",
    "        idx_val = idx[8000:]\n",
    "\n",
    "        labels_train = labels[idx_train]\n",
    "        features_train = features[idx_train]\n",
    "\n",
    "        labels_val = labels[idx_val]\n",
    "        features_val = features[idx_val]\n",
    "\n",
    "        min_eval = 1\n",
    "        best_lambda = 0\n",
    "\n",
    "        for l in lambdas:\n",
    "            cost = 1 / l\n",
    "            # train\n",
    "            prob = problem(labels_train, features_train)\n",
    "            param = parameter(f'-s 6 -c {cost}')\n",
    "            m = train(prob, param)\n",
    "\n",
    "            _, p_acc, _ = predict(labels_val, features_val, m)\n",
    "            eval_ = 1 - p_acc[0] / 100\n",
    "\n",
    "            if eval_ < min_eval:\n",
    "                min_eval = eval_\n",
    "                best_lambda = l\n",
    "            elif eval_ == min_eval:\n",
    "                # choose larger lambda\n",
    "                if l > best_lambda:\n",
    "                    best_lambda = l\n",
    "\n",
    "        # re-run training with best lambda on whole training set\n",
    "        prob = problem(labels, features)\n",
    "        param = parameter(f'-s 6 -c {1/best_lambda}')\n",
    "        best_model = train(prob, param)\n",
    "\n",
    "        _, p_acc_t, _ = predict(lables_t, features_t, best_model)\n",
    "        eout = 1 - p_acc_t[0] / 100\n",
    "\n",
    "        with open(result_file, 'a') as f:\n",
    "            f.write(f\"{best_lambda},{eout}\\n\")\n",
    "\n",
    "    print(\"problem 11 done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from liblinear.liblinearutil import *\n",
    "\n",
    "def problem12(result_file, round=1):\n",
    "    labels, features = read_data('mnist.scale.txt')\n",
    "    lables_t, features_t = read_data('mnist.scale.t.txt')\n",
    "\n",
    "    with open(result_file, 'w') as f:\n",
    "        f.write(\"lambda,eout\\n\")\n",
    "\n",
    "    lambdas = [0.01, 0.1, 1, 10, 100, 1000]\n",
    "\n",
    "    for i in range(round):\n",
    "        # spilt data set 3-fold cross validation\n",
    "        np.random.seed(i)\n",
    "        idx = np.random.permutation(labels.shape[0])\n",
    "\n",
    "        min_ecv = 1\n",
    "        best_lambda = 0\n",
    "\n",
    "        for l in lambdas:\n",
    "            cost = 1 / l\n",
    "\n",
    "            ecv = 1\n",
    "            # 3-fold cross validation\n",
    "            for m in range(3):\n",
    "                idx_train = idx[int(labels.shape[0] * m / 3):int(labels.shape[0] * (m+1) / 3)]\n",
    "\n",
    "                labels_train = labels[idx_train]\n",
    "                features_train = features[idx_train]\n",
    "\n",
    "                labels_val = labels[~idx_train]\n",
    "                features_val = features[~idx_train]\n",
    "\n",
    "                # train\n",
    "                prob = problem(labels_train, features_train)\n",
    "                param = parameter(f'-s 6 -c {cost}')\n",
    "                m = train(prob, param)\n",
    "\n",
    "                _, p_acc, _ = predict(labels_val, features_val, m)\n",
    "                em = 1 - p_acc[0] / 100\n",
    "\n",
    "                if em < ecv:\n",
    "                    ecv = em\n",
    "\n",
    "            if ecv < min_ecv:\n",
    "                min_ecv = ecv\n",
    "                best_lambda = l\n",
    "            elif ecv == min_ecv:\n",
    "                # choose larger lambda\n",
    "                if l > best_lambda:\n",
    "                    best_lambda = l\n",
    "\n",
    "        # re-run training with best lambda on whole training set\n",
    "        prob = problem(labels, features)\n",
    "        param = parameter(f'-s 6 -c {1/best_lambda}')\n",
    "        best_model = train(prob, param)\n",
    "\n",
    "        _, p_acc_t, _ = predict(lables_t, features_t, best_model)\n",
    "        eout = 1 - p_acc_t[0] / 100\n",
    "\n",
    "        with open(result_file, 'a') as f:\n",
    "            f.write(f\"{best_lambda},{eout}\\n\")\n",
    "\n",
    "    print(\"problem 12 done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> read mnist.scale.txt\n",
      "read labels:  (11876,)\n",
      "read features:  (11876, 728)\n",
      ">> read mnist.scale.t.txt\n",
      "read labels:  (1990,)\n",
      "read features:  (1990, 725)\n",
      "Accuracy = 98.8631% (3913/3958) (classification)\n",
      "Accuracy = 98.6865% (3907/3959) (classification)\n",
      "Accuracy = 98.5855% (3903/3959) (classification)\n",
      "Accuracy = 98.9136% (3915/3958) (classification)\n",
      "Accuracy = 98.6865% (3907/3959) (classification)\n",
      "Accuracy = 98.5097% (3900/3959) (classification)\n",
      "Accuracy = 98.5599% (3901/3958) (classification)\n",
      "Accuracy = 98.5602% (3902/3959) (classification)\n",
      "Accuracy = 98.3582% (3894/3959) (classification)\n",
      "Accuracy = 97.1703% (3846/3958) (classification)\n",
      "Accuracy = 97.3983% (3856/3959) (classification)\n",
      "Accuracy = 97.07% (3843/3959) (classification)\n",
      "Accuracy = 93.7847% (3712/3958) (classification)\n",
      "Accuracy = 94.2662% (3732/3959) (classification)\n",
      "Accuracy = 93.559% (3704/3959) (classification)\n",
      "Accuracy = 50.1769% (1986/3958) (classification)\n",
      "Accuracy = 49.0275% (1941/3959) (classification)\n",
      "Accuracy = 50.6441% (2005/3959) (classification)\n",
      "Accuracy = 98.4422% (1959/1990) (classification)\n",
      "Accuracy = 98.8631% (3913/3958) (classification)\n",
      "Accuracy = 98.7118% (3908/3959) (classification)\n",
      "Accuracy = 98.5602% (3902/3959) (classification)\n",
      "Accuracy = 98.8883% (3914/3958) (classification)\n",
      "Accuracy = 98.8128% (3912/3959) (classification)\n",
      "Accuracy = 98.535% (3901/3959) (classification)\n",
      "Accuracy = 98.5851% (3902/3958) (classification)\n",
      "Accuracy = 98.5602% (3902/3959) (classification)\n",
      "Accuracy = 98.4845% (3899/3959) (classification)\n",
      "Accuracy = 97.524% (3860/3958) (classification)\n",
      "Accuracy = 97.3731% (3855/3959) (classification)\n",
      "Accuracy = 96.9942% (3840/3959) (classification)\n",
      "Accuracy = 94.29% (3732/3958) (classification)\n",
      "Accuracy = 93.5085% (3702/3959) (classification)\n",
      "Accuracy = 93.1801% (3689/3959) (classification)\n",
      "Accuracy = 50.9853% (2018/3958) (classification)\n",
      "Accuracy = 48.9265% (1937/3959) (classification)\n",
      "Accuracy = 49.4064% (1956/3959) (classification)\n",
      "Accuracy = 98.593% (1962/1990) (classification)\n",
      "problem 12 done\n"
     ]
    }
   ],
   "source": [
    "problem10('result10.csv', 1126)\n",
    "problem11('result11.csv', 1126)\n",
    "problem12('result12.csv', 1126)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
